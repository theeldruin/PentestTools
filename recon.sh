#!/bin/bash

declare -i test=0
declare -i col=$(echo "$1" | sed 's/\./ /g' | awk '{print NF}')
declare alvo=$1
declare agente=$2

if [[ -z agente ]]
then
	agente="X-BugHunter: Myself"
fi

#Tools utilizadas = whatweb,gospider,subfinder,sublist3r,curl,eyewitness
#https://github.com/incogbyte/shosubgo
#https://github.com/OWASP/Amass
#https://github.com/hahwul/dalfox
#https://github.com/KathanP19/Gxss
#https://github.com/devanshbatham/ParamSpider
#https://github.com/tomnomnom/waybackurls
#https://github.com/s0md3v/uro
#https://github.com/lc/gau

ASN() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	### Enumerando ASN
	echo "---> Enumerando ASN"
	asn -m -n $alvo | sed 's/\x1B\[[0-9;]\{1,\}[A-Za-z]//g' | sed 's/\x1b//g' | sed 's/(B//g' | sed 's/\[m//g' >> asn.txt
}

DNS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	### Enumerando DNS
	echo "---> Enumerando DNS"
	#dnsrev.sh $alvo | sed 's/.*32m //' >> dns.txt
	dnsrev.sh $alvo >> dns.txt
}

SUBDOMINIOS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	### Enumerando Subdominios
	echo "---> Enumerando Subdominios"
	echo "------> Running Subfinder"
	echo $alvo | subfinder -silent > /tmp/temp.txt

	echo "------> Running Sublist3r"
	touch /tmp/sub.txt
	sublist3r -d $alvo -o /tmp/sub.txt 2>/dev/null 1>/dev/null
	cat /tmp/sub.txt >> /tmp/temp.txt

	echo "------> Running Gau"
	gau $alvo --subs | sort | uro >> /tmp/gau.txt
	cat /tmp/gau.txt | sort | uro >> /tmp/links.txt
	cat /tmp/gau.txt | cut -d "/" -f 1,2,3 | sort | uro >> /tmp/temp.txt

	echo "------> Running OWASP Amass"
	amass enum -brute -silent -d $alvo >> /tmp/temp.txt
		
	#Verificando sitemaps
	cat /tmp/temp.txt | grep $alvo | grep sitemap > sitemap.txt
	#xargs -a sitemap.txt -I@ sh -c 'curl $site -H $agente -p http://127.0.0.1:8080 -s >> /tmp/temp.txt'
	#xargs -a sitemap.txt -I@ sh -c 'curl $site -H $agente -s >> /tmp/temp.txt'

	### Filtrando subdominios encontrados e ativos
	echo "------> Verificando links que ainda estão ativos"
	cat /tmp/temp.txt | grep $alvo | sort | uro > /tmp/temp2.txt
	cat /tmp/temp2.txt | sort | uro | httpx -retries 2 -sc -H $agente -silent -fc 404 | sed 's/\[.*$//' >> /tmp/subdomains.txt

	# Testando e removendo os com código de retorno HTTP 404
	#echo "------> Filtrando resultados pelo http_code, removendo status 404"
	#cat /tmp/subdomains.txt  | $HOME/go/bin/httpx -follow-host-redirects -random-agent -retries 2 -title -web-server -tech-detect -location -sc -H $agente -silent -fc 404 -proxy "http://127.0.0.1:8080" | sed 's/\[.*$//' | sort | uro > /tmp/temp.txt
	#cat /tmp/subdomains.txt  | $HOME/go/bin/httpx -follow-host-redirects -random-agent -retries 2 -title -web-server -tech-detect -location -sc -H $agente -silent -fc 404 | sed 's/\[.*$//' | sort | uro > /tmp/temp.txt

	# Registrando os subdominios ativos encontrados
	cat /tmp/subdomains.txt | grep $alvo | sort | uro > /tmp/tree.txt
	cat /tmp/subdomains.txt | grep $alvo | sort | uro >> subdominios.txt
	
	cat /tmp/links.txt | grep $alvo | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sed 's/\/$//g' | sort | uro | grep $alvo | $HOME/go/bin/httpx -retries 2 -sc -H $agente -fc 404 -silent >> links.txt
}

CRAWLING() {		
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	# Crawling
	echo "---> Crawling"
	echo "------> Running gospider"
	#gospider -S $(cat /tmp/tree.txt | sed 's/^.*\/\///g' | sort | uro) -d 10 -p http://127.0.0.1:8080 >> /tmp/spi.txt
	xargs -a /tmp/tree.txt -I@ sh -c 'gospider -H $agente -s @ -d 10 -c 10 --other-source >> /tmp/spi.txt'
	cat /tmp/spi.txt | grep $alvo >> /tmp/spider.txt

	cat /tmp/spider.txt | grep "\[url\]" >> /tmp/url.txt
	cat /tmp/spider.txt | grep "\[linkfinder\]" >> /tmp/linkfinder.txt
	cat /tmp/spider.txt | grep "\[robots\]" >> /tmp/robots.txt
	cat /tmp/spider.txt | grep "\[form\]" >> /tmp/form.txt
	cat /tmp/spider.txt | grep "\[javascript\]" >> /tmp/javascript.txt

	# Organizando links encontrados encontradas
	#cat /tmp/linkfinder.txt | sed 's/.*from: http/http/'| egrep -v "MM|DD|YYYY|\.w3\.|- http|- application|- text|\.jpg|\.png" | cut -d ' ' -f4 | sed 's/\]//g' | sort | uro > /tmp/temp.txt
	#cat /tmp/robots.txt | cut -d " " -f3 | sort | uro >> /tmp/temp.txt
	#cat /tmp/url.txt | grep code-200 | cut -d " " -f5 | sort | uro >> /tBmp/temp.txt

	#cat /tmp/linkfinder.txt | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sort | uro > /tmp/temp.txt
	#cat /tmp/robots.txt | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sort | uro >> /tmp/temp.txt
	#cat /tmp/url.txt | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sort | uro >> /tmp/temp.txt
	#cat /tmp/links.txt | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sort | uro >> /tmp/temp.txt

	cat /tmp/linkfinder.txt | sort | uro >> linkfinder.txtB
	cat /tmp/robots.txt | sort | uro >> robots.txt
	cat /tmp/url.txt | sort | uro >> url.txt
	cat /tmp/form.txt | sort | uro >> form.txt
	cat /tmp/javascript.txt | sort | uro >> javascript.txt

	cat /tmp/spider.txt >> /tmp/links.txt
	cat /tmp/tree.txt >> /tmp/links.txtB
	cat /tmp/links.txt | grep $alvo | sed 's/^.*http/http/g' | sed 's/\].*$//g' | sed 's/\/$//g' | sort | uro | grep $alvo | $HOME/go/bin/httpx -retries 2 -sc -H $agente -fc 404 -silent >> links.txt
	cat links.txt | sed 's/\[.*$//g' | grep $alvo | sort | uro | grep $alvo | $HOME/go/bin/httpx -retries 2 -H $agente -silent -fc 404 >> crawling.txt

	#Criando arquivos de subdominios
	cat crawling.txt | grep $alvo | cut -d "/" -f 1,2,3 | sed 's/ //' | sort | uro >> subdominios.txt
}

HEADERS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Enumerando headers
	echo "---> Enumerando Headers"
	rm headers.txt 2>/dev/null

	xargs -a subdominios.txt -I@ sh -c 'echo @ >> headers.txt; curl -H $agente -s -I @ >> headers.txt; echo >> headers.txt'
}

WHOIS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Enumerando whois
	echo "---> Enumerando Whois"
	whois $alvo | grep -v '%' > whois.txt
}

ROBOTS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Verificando robots
	echo "---> Enumerando Robots"
	cat links.txt | grep robots > robots.txt
}

SCREENSHOTS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Tirando screenshots
	echo "---> Tirando Screenshots"
	{ eyewitness -f subdominios.txt --timeout 30 --no-prompt >> /dev/null; cp -s ./*/report.html .; }
}		

ARQUIVOS() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	#Coletando arquivos
	echo "---> Separando arquivos"
	cat links.txt | sed 's/\[.*$//g' | grep ".js" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > js.txt
	cat links.txt | sed 's/\[.*$//g' | grep ".css" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > css.txt
	cat links.txt | sed 's/\[.*$//g' | grep ".php" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > php.txt
	cat links.txt | sed 's/\[.*$//g' | grep "=" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > params.txt
	cat links.txt | sed 's/\[.*$//g' | grep "wp-" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > wordpress.txt
	cat links.txt | sed 's/\[.*$//g' | grep ".html" | sed 's/^.*http/http/g' | cut -d " " -f1 | sed 's/\]//g' > html.txt
}

WHATWEB() {
	#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	### Executando WhatWeb
	echo "---> WhatWeb"
	xargs -a subdominios.txt -I@ sh -c 'whatweb @ -H $agente --log-brief=/tmp/whatweb.txt; echo >> /tmp/whatweb.txt'

	cat /tmp/whatweb.txt | sed 's/\],/\]\n\t/g' | sed 's/\[200/\n\t\[200/g' | sed 's/\[302/\n\t\[302/g' | sed 's/Cookies/\n\tCookies/g' | sed 's/\t /\t/g' > whatweb.txt
}

NUCLEI() { #https://github.com/projectdiscovery/nuclei-templates
	echo "---> Nuclei"
	#echo "------> Takeover" >> nuclei.txt
	#nuclei -p http://127.0.0.1:8080 -t takeovers -l subdominios.txt >> nuclei.txt
	nuclei -itags misc -l subdominios.txt -silent -nc >> nuclei.txt
}

TESTES() {
	echo "---> Paramspider"
	xargs -a subdominios.txt -I@ sh -c "paramspider -d @ --exclude js,jpg,eot,jpeg,gif,css,tif,tiff,png,ttf,woff,woff2,ico,pdf,svg,txt,font -l high | grep = >> /tmp/params.txt"

	cat /tmp/params.txt | egrep -v ".js|.jpg|.eot|.jpeg|.gif|.css|.tif|.tiff|.png|.ttf|.woff|.woff2|.ico|.pdf|.svg|.txt|.font"| Gxss -p eldruin -h $agente | sort | uro > params.txt

	echo "---> Dalfox (SQLi,SSTI, Open Redirect, CRLF Injection e XSS)"
	cat params.txt | dalfox pipe --blind https://eldruin.xss.ht -S -H $agente -w 1 >> finds.txt

}

NOTIFY() {
	notify -silent -bulk -data finds.txt
	notify -silent -bulk -data nuclei.txt
}

recon () {
	rm -f /tmp/* 2>/dev/null
	rm -f $arquivo 2>/dev/null

	mkdir $alvo 2>/dev/null
	cd $alvo 2>/dev/null
	rm -rf *

	echo "---> Scan iniciado"
	echo "---> Enquanto aguarda a finalização visite os GitDorks do arquivo gdorks.txt e veja se aparece algo interessante ;)"
	gdork.sh $alvo >> gdork.txt
	echo		

	ASN
	DNS
	WHOIS
	SUBDOMINIOS
	#CRAWLING
	HEADERS
	ROBOTS
	SCREENSHOTS
	ARQUIVOS
	WHATWEB
	#NUCLEI
	#TESTES
	#NOTIFY

	rm geckodriver.log 2>/dev/null
	#rm /tmp/* 2>/dev/null
}

if [[ $# -ne 1 || $col -lt 2 || $col -gt 4 ]]
then
	echo -e "Bem vindo ao Recon.sh\n"
	echo -e "Este script irá fazer um reconhecimento do alvo selecionado, criar uma pasta com o nome do alvo e arquivos referentes a cada etapa do reconhecimento"
	echo -e "Forma de uso ---> ./recon.sh DOMINIO"
	echo -e "\t Exemplo: ./recon.sh google.com"
	echo -e "\t Exemplo: ./recon.sh google.com.br"
	echo
else
	declare -x host=$(echo $1 | cut -d "/" -f3 | cut -d " " -f1 )
	recon $alvo
fi		
